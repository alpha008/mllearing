{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于逻辑回归的泰坦尼克存活预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、实验简介"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （一）问题描述"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "泰坦尼克号是当时世界上最大的豪华客轮，被称为是“永不沉没的客轮”或是“梦幻客轮”。1912年4月10日，泰坦尼克号从英国南安普敦出发,计划中的目的地为美国的纽约,开始了这艘“梦幻客轮”的处女航。4月14日晚11点40分，泰坦尼克号在北大西洋撞上冰山，在4月15日凌晨2点20分沉没。由于缺少足够的救生艇，导致2224名乘客和机组人员中的1502人死亡。\n",
    "\n",
    "尽管在逃生的过程中有一些运气因素的影响，但是否有某些群体的人比其他人更容易存活下来？（比如女人，孩子和上流社会的人等）。\n",
    "\n",
    "本实验将借助乘客资料，例如姓名、年龄、性别、社会经济阶层等，使用逻辑回归算法来建立一个回答：“什么样的人更有可能幸存？”问题的预测模型。这里的预测实质就是幸存还是遇难的二分类问题，实验采用Sklearn机器学习库中的逻辑回归算法模型，并以乘客是否存活为因变量进行预测分析，最终得到乘客幸存的结果以及预测的准确率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （二）数据介绍\n",
    "本实验中的数据集来自来自Kaggle竞赛平台的入门项目Titanic:Machine Learning from Disaster，数据集总共有891个样本数据，每个样本包含12个特征，其中，PassengerId表示样本编号；Survived表示是否幸存（1表幸存，0表示遇难），在实验中用于算法标签；其它10个特征的详细情况如下：\n",
    "\n",
    "|特征名|特征含义|\n",
    "|---|---|\n",
    "|Pclass|舱位等级，分为一等舱、二等舱、三等舱|\n",
    "|Name|乘客姓名|\n",
    "|Sex|性别，Male或Female|\n",
    "|Age|年龄|\n",
    "|SibSp|兄弟姐妹、堂兄弟姐妹人数|\n",
    "|Parch|父母与子女个数|\n",
    "|Ticket|船票信息（上面记载着座位号）|\n",
    "|Fare|票价|\n",
    "|Cabin|客舱|\n",
    "|Embarked|登船港口|\n",
    "\n",
    "\n",
    "实验中，将数据集按8:2分成训练集和测试集。\n",
    "\n",
    "数据集文件所在的位置“逻辑回归\\titanic\\train.csv”。\n",
    "\n",
    "本实验将利用上述Titanic数据集的训练集训练逻辑回归模型，并使用测试集对训练好的模型进行预测和验证，计算模型的准确率等评价指标。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （三）技术要求\n",
    "#### 1.环境要求\n",
    "\n",
    "（1）Python 3.x（包括Pandas、Matplotlib、Numpy和Sklearn包）。\n",
    "\n",
    "（2）Jupyter Notebook。\n",
    "\n",
    "（3）Windows 7及以上和Linux操作系统下运行。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.技术说明\n",
    "\n",
    "（1）Python3.x 语言程序设计。\n",
    "\n",
    "（2）Sklearn-0.21.3。\n",
    "\n",
    "（3）逻辑回归算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、实验目的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （一）知识目标\n",
    "\n",
    "1.理解逻辑回归的基本原理，学会对数据集进行分析。\n",
    "\n",
    "2.掌握利用Sklearn库中的逻辑回归算法，以及该算法的使用方法。\n",
    "\n",
    "3.学会利用逻辑回归算法对真实数据集进行分类预测的编程和调试能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （二）技能目标\n",
    "1.熟练掌握Sklearn库中逻辑回归的实现与调试方法。\n",
    "\n",
    "2.进一步熟悉Python语言中Sklearn机器学习算法库的使用方法。\n",
    "\n",
    "3.掌握数据分析及应用的流程和程序设计的方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （三）素养目标\n",
    "1.提高学生的数据分析能力。\n",
    "\n",
    "2.锻炼学生应用程序设计文档的撰写能力。\n",
    "\n",
    "3.提高学生应用程序的编码规范能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、 实验任务"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T06:54:48.583773Z",
     "start_time": "2019-10-24T06:54:48.577816Z"
    }
   },
   "source": [
    "本实验主要任务是应用sklearn调用逻辑回归模块，通过将891个样本中的80%作为训练集对逻辑回归模型进行训练，并使用训练后的模型对其余20%的样本数据进行预测。  \n",
    "具体的实验要求如下：  \n",
    "1.数据集的观察：加载数据集，观察数据集的整体情况，并观察数据的行、列数以及各个数据的数据类型。  \n",
    "\n",
    "2.数据可视化：绘出数据集中Cabin和标签Survived的关系图（直方图），观察这二者之间的联系，并判断是否舍弃Cabin这列特征。  \n",
    "\n",
    "3.数据处理：综合运用独热编码、缺失值处理等方法实现数据的清洗，把数据全部变成数值型特征，之后再对特征数据进行进行处理（如缩放或标准化），以便于模型训练，减少计算量。  \n",
    "\n",
    "4.数据集的划分：将数据集按8:2划分成训练集和测试集。\n",
    "\n",
    "5.模型训练：用训练集对逻辑回归模型进行训练。\n",
    "\n",
    "6.模型的评估：用测试集评估逻辑回归模型的分类预测的准确度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四、实验步骤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （一）加载相关的包"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T06:54:48.696479Z",
     "start_time": "2019-10-24T06:54:48.591Z"
    }
   },
   "source": [
    "1.加载numpy、pandas等包做数据处理。 \n",
    "\n",
    "2.加载matplotlib包做数据可视化来并分析数据。\n",
    "\n",
    "3.从sklearn.linear_model加载LogisticRegression算法函数。\n",
    "\n",
    "4.从sklearn.preprocessing中加载StandardScaler函数。\n",
    "\n",
    "5.从sklearn.model_selection中加载train_test_split训练集-测试集划分的函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T07:52:59.218546Z",
     "start_time": "2020-02-25T07:52:57.559946Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np  # 数据处理包\n",
    "import pandas as pd  # 文件读取包\n",
    "import matplotlib.pyplot as plt  # 数据可视化包\n",
    "from sklearn.preprocessing import StandardScaler  # 数据标准化\n",
    "from sklearn.linear_model import LogisticRegression  # 逻辑回归模型\n",
    "from sklearn.model_selection import train_test_split  # 数据划分函数\n",
    "\n",
    "import warnings  # 警告信息函数\n",
    "warnings.filterwarnings('ignore')  # 忽略警告信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （二）数据集的观察"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-23T03:27:51.729561Z",
     "start_time": "2019-10-23T03:27:51.724627Z"
    }
   },
   "source": [
    "（1）利用Pandas中的read_csv()方法来读取csv格式的数据文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T07:52:59.232467Z",
     "start_time": "2020-02-25T07:52:59.220499Z"
    }
   },
   "outputs": [],
   "source": [
    "# 加载数据文件。注意加载数据文件的方式。\n",
    "train = pd.read_csv(\"titanic/train.csv\")  # 加载训练集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（2）利用pandas中的head()函数来查看整个dataframe中的前五行数据，直观的了解数据内容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T07:52:59.258399Z",
     "start_time": "2020-02-25T07:52:59.234490Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()  # 观察数据的前五行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（3）利用pandas中的info()函数来查看数据集的大小、行列规模以及数据类型等信息，以便于后续数据处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T07:52:59.274366Z",
     "start_time": "2020-02-25T07:52:59.260394Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()  # 观察数据的整体信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T01:47:31.316650Z",
     "start_time": "2019-10-24T01:47:31.311643Z"
    }
   },
   "source": [
    "观察上述数据信息可得：  \n",
    "Embarked这一列缺失了两条 ，Age这一列缺失了一百多条数据，Cabin这一列只有204条记录。由于模型训练时需要一个无缺失值的数据，后序需将这三个特征的缺失值进行处理。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（4）利用pandas的describe()函数查看数据集的描述性统计信息。（因为有些特征是文本特征，比如Name、Sex、Ticket、Embarked，这些特征的统计信息是看不到的）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T07:52:59.316249Z",
     "start_time": "2020-02-25T07:52:59.276359Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()#数据集的统计数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上表结果可以得出，生存率平均值为0.383838，说明遇难人数一大半；Pclass的平均值为2.3，说明坐3等舱的乘客居多，因为通常3等舱的价格最便宜舱位；平均年龄29.7岁，有可能很多成年人带了年幼的小孩，导致平均年龄较小等等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （三）数据可视化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于Cabin缺失比较多,需要具体观察此特征的内容，可以利用pandas.value_counts()函数来对Cabin这列特征的类别进行统计。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T07:52:59.328226Z",
     "start_time": "2020-02-25T07:52:59.318238Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B96 B98        4\n",
       "G6             4\n",
       "C23 C25 C27    4\n",
       "C22 C26        3\n",
       "F33            3\n",
       "              ..\n",
       "E34            1\n",
       "C7             1\n",
       "C54            1\n",
       "E36            1\n",
       "C148           1\n",
       "Name: Cabin, Length: 147, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Cabin.value_counts()# 统计特征Cabin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过观察特征Cabin的统计信息，很难看出问题来，数据集也没说明G6，C23， C25等这一类的信息具体代表什么意思。为了进一步的分析此特征，可以绘画出此特征的直方图进行统计。\n",
    "\n",
    "首先利用plt.figure(figsize=(10,8))函数创建一张画布（图形实例），再利用pd.notnull()和pd.isnull()进行空值和非空值的判断，通过索引的方式获取Cabin有值和为空值的数量，并利用value_counts()函数获取相对于Survived里获救和遇难的计数，最后把获取的数据合成新的DataFrame数据，并利用pandas里自制的绘制图的函数plot()绘画出有无Cabin和Survived之间的直方图。\n",
    "\n",
    "plt.figure()函数所使用的参数示意：\n",
    "\n",
    "    figsize：设置画布的大小，其中10代表画布的长度，8代表画布的高度\n",
    "    \n",
    "plot()函数所使用的参数示意：\n",
    "\n",
    "    kind：表示图形种类，默认为折线图（line），可以为条形图（bar），横向条形图（barh），柱状图（hist）等\n",
    "    stacked：判断图片中是否有子图，True或False\n",
    "\n",
    "pd.notnull()函数返回值为布尔型的矩阵，非空值为True，空值为False；pd.isnull()则相反。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T07:52:59.590511Z",
     "start_time": "2020-02-25T07:52:59.331204Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family ['SimHei'] not found. Falling back to DejaVu Sans.\n",
      "findfont: Font family ['SimHei'] not found. Falling back to DejaVu Sans.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['font.family'] = 'SimHei'  # 设置字体序列为简黑，解决plt中中文显示问题。\n",
    "plt.figure(figsize=(10, 8))  # 图的长度和宽度的参数\n",
    "# 获取Cabin有值的数量，并相对于Survived里获救和遇难的计数\n",
    "Survived_cabin = train.Survived[pd.notnull(train.Cabin)].value_counts()\n",
    "# 获取Cabin为空值的数量，并相对于Survived里获救和遇难的计数\n",
    "Survived_nocabin = train.Survived[pd.isnull(train.Cabin)].value_counts()\n",
    "\n",
    "# 把获取的数据合成新的DataFrame数据\n",
    "df = pd.DataFrame({u'有cabin': Survived_cabin, u'无cabin': Survived_nocabin})\n",
    "df = df.transpose()  # 对新的DataFrame数据进行转置\n",
    "\n",
    "df.plot(kind='bar', stacked=True)  # 对数据绘制直方图，可以用来观察数据之间的关系，图的类型有kind参数指定\n",
    "plt.xlabel(u'有无cabin', size=15, rotation=0)  # x轴\n",
    "plt.ylabel(u'人数', size=15)  # y轴\n",
    "plt.title(u'按cabin有无看获救情况', size=15)  # 为图加上标题\n",
    "plt.legend((u'未获救', u'获救'), loc='best')  # 图例\n",
    "plt.grid(b=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （四）数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（1）通过观察上面直方图，有Cabin信息的获救概率明显大于无Cabin信息,这可能意味着本来就没有这些信息就是对的，所以可以将特征Cabin制作成一列类别特征。 \n",
    "\n",
    "制作类别特征的方法，可以通过索引分别获取有无Cabin信息的数据，并将它改写为‘Yes’和‘No’。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T07:52:59.604499Z",
     "start_time": "2020-02-25T07:52:59.594499Z"
    }
   },
   "outputs": [],
   "source": [
    "train.loc[(train.Cabin.notnull()), 'Cabin'] = \"Yes\"\n",
    "train.loc[(train.Cabin.isnull()), 'Cabin'] = \"No\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T07:37:39.425210Z",
     "start_time": "2019-10-24T07:37:39.409252Z"
    }
   },
   "source": [
    "（2）对于Age这列特征，缺失值的个数并不是特别多，可以使用此列特征的mean代替缺失值，缺失值的替换可以调用fillna(mean)函数实现。\n",
    "\n",
    "fillna()函数所使用的参数示意：\n",
    "\n",
    "    value：用于填充缺失值\n",
    "    inplace：默认值 False ，是否替换原来的内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T07:52:59.613448Z",
     "start_time": "2020-02-25T07:52:59.607466Z"
    }
   },
   "outputs": [],
   "source": [
    "train.Age.fillna(train.Age.mean(), inplace=True)  # 对数值类型的特征的缺失值用均值填充"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（3）对于Embarked特征的缺失值，可以进行众数的填充，填充的方法为fillna(train.Embarked.mode()[0])。处理完缺失值后，再利用train.isnull().sum()来统计缺失值的个数，以防数据的缺失。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T07:52:59.624419Z",
     "start_time": "2020-02-25T07:52:59.616441Z"
    }
   },
   "outputs": [],
   "source": [
    "train.Embarked.fillna(train.Embarked.mode()[0], inplace=True)#众数填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T07:52:59.639385Z",
     "start_time": "2020-02-25T07:52:59.626413Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()[train.isnull().sum() > 0]  # 缺失值判断"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（4）由于PassengerId这一列并不是特征属性，而是数据集的一个样本编号，在数据处理时需要删除，删除此列的操作可以利用drop()函数实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T07:52:59.648356Z",
     "start_time": "2020-02-25T07:52:59.642371Z"
    }
   },
   "outputs": [],
   "source": [
    "# 删除数据集的样本编号列\n",
    "train.drop(\"PassengerId\", axis=1, inplace=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（5）由于逻辑回归模型中需要使用数值型的特征数据，对于Name和Ticket两个文本特征，几乎每一条记录都是一个完全不同的值，无法转换成一个较好的数值特征，需要利用pandas.drop(\"列名\")方法删掉这两列特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T07:52:59.672291Z",
     "start_time": "2020-02-25T07:52:59.665310Z"
    }
   },
   "outputs": [],
   "source": [
    "#删除无用特征\n",
    "train.drop([\"Name\", \"Ticket\"], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（6）由于独热编码解决了分类器不好处理属性数据的问题，在一定程度上也起到了扩充特征的作用。可以将Embarked，Sex，Pclass这三个离散特征和处理后的Cabin特征进行独特编码，独热编码可以利用pandas下的get_dummies(X)实现。\n",
    "\n",
    "get_dummies()函数所使用的参数示意：\n",
    "\n",
    "    data：array-like、Series或者DataFrame\n",
    "        输入的数据\n",
    "    prefix：string、含字符串的list、含字符串的dict,默认为None\n",
    "        指定需要实现类别转换的列名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T07:52:59.697252Z",
     "start_time": "2020-02-25T07:52:59.674285Z"
    }
   },
   "outputs": [],
   "source": [
    "#独热编码\n",
    "dummies_Cabin = pd.get_dummies(train['Cabin'], prefix='Cabin')\n",
    "\n",
    "dummies_Embarked = pd.get_dummies(train['Embarked'], prefix='Embarked')\n",
    "\n",
    "dummies_Sex = pd.get_dummies(train['Sex'], prefix='Sex')\n",
    "\n",
    "dummies_Pclass = pd.get_dummies(train['Pclass'], prefix='Pclass')\n",
    "\n",
    "# 用concat函数将这些新的属性连接到dataframe中\n",
    "train = pd.concat([train, dummies_Cabin, dummies_Embarked, dummies_Sex, dummies_Pclass], axis=1)\n",
    "\n",
    "# 再通过drop函数将原先的Pclass、Sex、Cabin和Embarked这四个属性从dataframe中去掉\n",
    "train.drop(['Pclass', 'Sex', 'Cabin', 'Embarked'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（7）本实验中，由于Survived是标签，所以把它单独取出来，采用Pandas中取某一列的方法取出标签列数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T07:52:59.704209Z",
     "start_time": "2020-02-25T07:52:59.699219Z"
    }
   },
   "outputs": [],
   "source": [
    "y = train[\"Survived\"]#获取标签列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取了标签后，需要利用pandas下的drop(列名，axis=1指定为列，inplace=是否替换原来的内容)函数删除标签列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T07:52:59.713181Z",
     "start_time": "2020-02-25T07:52:59.706200Z"
    }
   },
   "outputs": [],
   "source": [
    "X = train.drop(['Survived'], axis=1)# 删除标签列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（8）数据标准化\n",
    "\n",
    "因为数据标准化可以降低计算量，同时不会影响逻辑回归模型预测的准确率。实验中调用Sklearn中StandardScaler().fit_transform(X)函数来对未进行处理的连续特征进行标准化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T07:52:59.725149Z",
     "start_time": "2020-02-25T07:52:59.715176Z"
    }
   },
   "outputs": [],
   "source": [
    "#标准化特征数据\n",
    "std = StandardScaler()  \n",
    "X['Age'] = std.fit_transform(X['Age'].values.reshape(-1, 1))\n",
    "X['Fare'] = std.fit_transform(X['Fare'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T07:52:59.743102Z",
     "start_time": "2020-02-25T07:52:59.727144Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin_No</th>\n",
       "      <th>Cabin_Yes</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.592481</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.502445</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.638789</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.786845</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.284663</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.488854</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.407926</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.420730</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.407926</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.486337</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  SibSp  Parch      Fare  Cabin_No  Cabin_Yes  Embarked_C  \\\n",
       "0 -0.592481      1      0 -0.502445         1          0           0   \n",
       "1  0.638789      1      0  0.786845         0          1           1   \n",
       "2 -0.284663      0      0 -0.488854         1          0           0   \n",
       "3  0.407926      1      0  0.420730         0          1           0   \n",
       "4  0.407926      0      0 -0.486337         1          0           0   \n",
       "\n",
       "   Embarked_Q  Embarked_S  Sex_female  Sex_male  Pclass_1  Pclass_2  Pclass_3  \n",
       "0           0           1           0         1         0         0         1  \n",
       "1           0           0           1         0         1         0         0  \n",
       "2           0           1           1         0         0         0         1  \n",
       "3           0           1           1         0         1         0         0  \n",
       "4           0           1           0         1         0         0         1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()  # 查看处理完后数据前五行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （五）数据集的划分  \n",
    "由于本实验只提供一个数据集，因此需要将数据集划分为训练集与测试集，可以采用sklearn.preprocess模块下的train_test_split(X,y，test_size=0.2)函数来划分数据集。使用训练集训练模型，用测试集测试模型的正确率，以验证模型的有效性。函数train_test_split()里参数分别代表特征，标签，测试集的百分比。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T07:52:59.756067Z",
     "start_time": "2020-02-25T07:52:59.745097Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((712, 14), (712,), (179, 14), (179,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#划分数据集\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2)\n",
    "train_X.shape, train_y.shape, test_X.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （四）模型的训练、应用和评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型训练的具体实现步骤如下：\n",
    "\n",
    "1.实例化sklearn.linear_model里的LogisticRegression()算法模块。\n",
    "\n",
    "2.利用LogisticRegression().fit(train_X,train_y)函数对训练集数据进行拟合。\n",
    "\n",
    "3.利用model.predict(test_X)函数对测试集数据进行预测。\n",
    "\n",
    "4.利用模型里自带评估函数score(test_X, test_y)评估模型的准确度。\n",
    "\n",
    "LogisticRegression()函数所使用的参数示意：\n",
    "\n",
    "    C: 正则化系数λ的倒数，默认为1。\n",
    "    \n",
    "    penalty: 惩罚项，str类型，可选参数为l1和l2，默认为l2。penalty参数的选择会影响我们损失函数优化算法的选择，即参数solver的选择。如果是L2正则化，那么4种可选的算法{‘newton-cg’，‘lbfgs’， ‘liblinear’， ‘sag’}都可以选择，但是如果penalty是L1正则化的话，只能选择‘liblinear’。\n",
    "    \n",
    "    tol:迭代终止判据的误差范围，默认为1e-4。\n",
    "    \n",
    "    solver：优化算法选择参数，有五个可选参数，即newton-cg,lbfgs,liblinear,sag,saga。默认为liblinear。\n",
    "本实验中将对LogisticRegression()函数的参数penalty取两个不同的值，以比较不同的惩罚项对算法准确率的影响，最后利用逻辑回归算法函数自带的方法score(test_X, test_y)对这两个模型的准确率进行评估。   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T07:52:59.763048Z",
     "start_time": "2020-02-25T07:52:59.758062Z"
    }
   },
   "outputs": [],
   "source": [
    "# 实例化算法LogisticRegression()\n",
    "model_1 = LogisticRegression(C=1.0, tol=1e-6)\n",
    "model_2 = LogisticRegression(C=1.0, tol=1e-6, solver='sag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T07:52:59.800946Z",
     "start_time": "2020-02-25T07:52:59.769032Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(solver='sag', tol=1e-06)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型训练\n",
    "model_1.fit(train_X, train_y)  \n",
    "model_2.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T07:52:59.811917Z",
     "start_time": "2020-02-25T07:52:59.802942Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 用测试集测试得到预测标签\n",
    "model_1.predict(test_X)  \n",
    "model_2.predict(test_X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T07:52:59.824882Z",
     "start_time": "2020-02-25T07:52:59.815907Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7430167597765364, 0.7430167597765364)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 评分\n",
    "model_1.score(test_X, test_y),model_2.score(test_X, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 五、结果分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本实验所需解决的是Titanic数据集的二分类问题，正好适合逻辑回归。实验实现了利用Sklearn中的逻辑回归算法模块对Titanic数据集的预测，实验分为数据的加载、数据可视化、数据处理、数据集的划分、算法模型的训练、算法的应用和评估。\n",
    "\n",
    "本实验使用了liblinear和sag这两种优化算法的参数，最终准确率都达到了81%，并无差别。但在实际应用当中，优化算法参数liblinear比较适合于小数据集，而sag适用于大数据集，能提高模型训练时的速度。在利用机器学习算法之前，一个重要问题就是如何处理缺失数据，缺失过多的特征通常都会进行删除，而本实验是通过对该特征进行分析，将它构建成一个新特征，这个问题的解决方案并没有标准答案，它取决于实际应用中的需求。    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 六、实验拓展"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.查找关于此数据集的相关背景知识，认真观察数据集里的数据特征，对数据进行不同的处理方式，再通过得到结果进行分析。比如：对于年龄的本身也未必是一件非常靠谱的事情，在日常生活中，小朋友和老人可能得到的照顾会多一些。这样看的话，年龄作为一个连续值，给一个固定的值，似乎体现不出两头受照顾的实际情况，所以，将年龄这列特征离散化，按区段分作类别属性会更合适一些。  \n",
    "\n",
    "2.尝试使用不同分类算法对此数据集进行训练和预测，以对比的方式了解不同算法的优缺点。\n",
    "\n",
    "3.通过网络资源，查找数据量较大的数据集，再使用逻辑回归对此数据集进行分析，观察逻辑回归在不同数据集上的应用能力，加深对逻辑回归的理解。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "66e3d188d02a210bab72f20c506ffac958ef9b0a7153119813a4060f203dc33d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
